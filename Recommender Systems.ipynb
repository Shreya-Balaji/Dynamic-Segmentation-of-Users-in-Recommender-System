{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f2619e83",
   "metadata": {},
   "source": [
    "# Segmenting Users Dynamically- Recommender Systems"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1c43f08",
   "metadata": {},
   "source": [
    "Captures user-item interactions\n",
    "Dynamically segments users based on their preferences\n",
    "Segments all new users and recommends most popular choices "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e1308d0c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similarity Matrix:\n",
      "[[1.         0.66666667 0.66666667 0.66666667 0.66666667]\n",
      " [0.66666667 1.         0.33333333 0.66666667 0.66666667]\n",
      " [0.66666667 0.33333333 1.         0.33333333 0.66666667]\n",
      " [0.66666667 0.66666667 0.33333333 1.         0.33333333]\n",
      " [0.66666667 0.66666667 0.66666667 0.33333333 1.        ]]\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('CustomData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ac6626b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VBALA\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\VBALA\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User Labels: [0 0 1 0 1]\n"
     ]
    }
   ],
   "source": [
    "# Group distinct users with the same product tag\n",
    "grouped = df.groupby(['ProductTag', 'UserID']).size().reset_index(name='Count')\n",
    "# Display the grouped data\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "739adce7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for User 1: ['D']\n",
      "Recommendations for User 2: ['B']\n",
      "Recommendations for User 3: ['A']\n",
      "Recommendations for User 4: ['C']\n",
      "Recommendations for User 5: ['B']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "# Train FastText model on product tags\n",
    "model = FastText(sentences=[product_tags], min_count=1, vector_size=100, window=5, sg=1)\n",
    "\n",
    "# Function to find similar product tags based on FastText embeddings\n",
    "def find_similar_tags(tags):\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "    return similar_groups\n",
    "\n",
    "# Find similar product tags\n",
    "similar_groups = find_similar_tags(product_tags)\n",
    "\n",
    "# Display similar groups\n",
    "for group in similar_groups:\n",
    "    print(\"Similar group:\", group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "aa93ad73",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\VBALA\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1412: FutureWarning: The default value of `n_init` will change from 10 to 'auto' in 1.4. Set the value of `n_init` explicitly to suppress the warning\n",
      "  super()._check_params_vs_input(X, default_n_init=10)\n",
      "C:\\Users\\VBALA\\anaconda3\\Lib\\site-packages\\sklearn\\cluster\\_kmeans.py:1436: UserWarning: KMeans is known to have a memory leak on Windows with MKL, when there are less chunks than available threads. You can avoid it by setting the environment variable OMP_NUM_THREADS=1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Updated Recommendations for User 1: ['D']\n",
      "Updated Recommendations for User 2: ['B']\n",
      "Updated Recommendations for User 3: ['A']\n",
      "Updated Recommendations for User 4: ['C']\n",
      "Updated Recommendations for User 5: ['B']\n",
      "Updated User Clusters:\n",
      "User 1 belongs to Cluster 1\n",
      "User 2 belongs to Cluster 1\n",
      "User 3 belongs to Cluster 0\n",
      "User 4 belongs to Cluster 1\n",
      "User 5 belongs to Cluster 0\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "\n",
    "model = Word2Vec([product_tags], min_count=1, vector_size=100)  # Adjust parameters as needed\n",
    "\n",
    "def find_similar_tags(tags, max_groups=5):  # Specify the maximum number of groups\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "            if len(similar_groups) >= max_groups:  # Check if the maximum number of groups is reached\n",
    "                break\n",
    "    \n",
    "    # Create a dictionary to map each tag to its corresponding group\n",
    "    tag_to_group = defaultdict(list)\n",
    "    for group in similar_groups:\n",
    "        for tag in group:\n",
    "            tag_to_group[tag].append(group)\n",
    "    \n",
    "    # Assign each tag to the most similar group\n",
    "    assigned_groups = []\n",
    "    for tag in tags:\n",
    "        if tag_to_group[tag]:  # Check if the list of groups for the tag is not empty\n",
    "            most_similar_group = max(tag_to_group[tag], key=lambda x: len(set(x) & set(tags)))\n",
    "            if most_similar_group not in assigned_groups:\n",
    "                assigned_groups.append(most_similar_group)\n",
    "    \n",
    "    return assigned_groups\n",
    "\n",
    "assigned_groups = find_similar_tags(product_tags)\n",
    "\n",
    "for group in assigned_groups:\n",
    "    print(\"Assigned group:\", group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3f84db85",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recommendations for New User 1: ['A', 'C', 'B', 'D', 'E']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming df contains user data with columns UserID and ProductTag\n",
    "# and assigned_groups contains the assigned groups as obtained previously\n",
    "\n",
    "# Create a dictionary to map each product tag to its corresponding group(s)\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(list)\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].append(user)\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "136b79de",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize empty lists\n",
    "user_ids = []\n",
    "product_tags = []\n",
    "city_names = []\n",
    "product_ids = []\n",
    "\n",
    "# Generate 15 data points for each field\n",
    "\n",
    "user_ids.extend([''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=3)) for _ in range(15)])\n",
    "product_tags.extend(random.choices(['tech', 'fashion', 'skincare', 'makeup', 'electronics', 'beauty', 'gadgets', 'outdoor', 'sports', 'health', 'fitness', 'toys', 'books', 'kitchenware', 'jewelry', 'watches', 'automotive', 'pets', 'travel', 'gaming', 'music', 'art', 'photography', 'diy', 'craft', 'stationery', 'baby', 'food', 'drinks', 'gardening', 'camping'], k=15))\n",
    "city_names.extend(random.choices(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville', 'San Francisco', 'Indianapolis', 'Columbus', 'Fort Worth', 'Charlotte', 'Seattle', 'Denver', 'Washington', 'Boston', 'El Paso', 'Detroit', 'Nashville', 'Portland', 'Memphis', 'Oklahoma City'], k=15))\n",
    "product_ids.extend([str(random.randint(100000, 999999)) for _ in range(15)])\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'UserID': user_ids,\n",
    "    'ProductTag': product_tags,\n",
    "    'Region': city_names,\n",
    "    'ProductID': product_ids\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Read existing CustomData.csv file\n",
    "existing_data = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Concatenate existing data with new data\n",
    "updated_data = pd.concat([existing_data, df])\n",
    "\n",
    "# Write updated DataFrame to CSV\n",
    "updated_data.to_csv('CustomData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6ece97",
   "metadata": {},
   "outputs": [],
   "source": [
    "df=pd.read_csv('CustomData.csv')\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(set)  # Changed to set to ensure distinct values\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].add(user)  # Use add instead of append for sets\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {list(users)}\")  # Convert set to list for printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c779886",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Define the new user's region\n",
    "new_user_region = 'Kolkata'\n",
    "\n",
    "# Find the group with the maximum users\n",
    "group_with_max_users = max(groups_users, key=lambda x: len(groups_users[x]))\n",
    "\n",
    "# Find users from the same region as the new user\n",
    "users_from_same_region = [user for user, region in zip(df['UserID'], df['Region']) if region == new_user_region]\n",
    "if len(users_from_same_region)>0:\n",
    "    print('User(s) from same region: ',users_from_same_region)\n",
    "# Add the new user 'xyz' to the group with the maximum users\n",
    "group_with_max_users_users = set(groups_users[group_with_max_users])\n",
    "group_with_max_users_users.add('xyz')\n",
    "groups_users[group_with_max_users] = group_with_max_users_users\n",
    "\n",
    "# If users from the same region exist, add 'xyz' to the corresponding group\n",
    "if users_from_same_region:\n",
    "    user_from_same_region = users_from_same_region[0]  # Assuming only one user from the same region\n",
    "    group_with_same_region = next((group for group, users in groups_users.items() if user_from_same_region in users), None)\n",
    "    if group_with_same_region is not None:\n",
    "        group_with_same_region_users = set(groups_users[group_with_same_region])\n",
    "        group_with_same_region_users.add('xyz')\n",
    "        groups_users[group_with_same_region] = group_with_same_region_users\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03ca0a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_groups_users= pd.DataFrame(sorted_groups_users, columns=['Group', 'Users'])\n",
    "df_groups_users= df_groups_users.drop(columns=['Group'])\n",
    "df_groups_users['Assigned_Group'] = [assigned_groups[group] for group, _ in sorted_groups_users]\n",
    "df_groups_users.to_csv('Output.csv', index=False)\n",
    "df_groups_users.head()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
