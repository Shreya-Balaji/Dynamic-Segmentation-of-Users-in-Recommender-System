{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4eacad",
   "metadata": {},
   "source": [
    "# Dynamic Segmentation of Users in a Recommender System with Appropriate Privacy Preserving Techniques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "169500e3",
   "metadata": {},
   "source": [
    "Algorithm of this Recommender System:\n",
    "\n",
    "-A custom dataset is created which includes UserID, Region, ProductID, ProductTag.\n",
    "\n",
    "-Word2Vec technique is used to group similar ProductTag into a pre-defined number of groups.\n",
    "\n",
    "-Further, users who have viewed/purchased those products are assigned to the same number of groups. \n",
    "\n",
    "-We generate more data for the custom dataset. Now, the new dataset includes both old and new data. \n",
    "\n",
    "-We will again reassign the groups and show that as and when the user views a new product, they are assigned to a new group.\n",
    "Also, this algorithm deals with cold start problem by taking the personal details of user and using that and mapping user to relevant group. The user is also assigned to the group with maximum users. \n",
    "\n",
    "-For preserving the privacy of these data, we apply three encryption techniques, DES, AES and a combination of AES and ECC. Data is encrypted, stored in excel and read from excel and decrypted for further processing. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c1faa6",
   "metadata": {},
   "source": [
    "# FetchData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "de4280ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc</td>\n",
       "      <td>New York</td>\n",
       "      <td>879652</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bde</td>\n",
       "      <td>London</td>\n",
       "      <td>345871</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sed</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>998743</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdj</td>\n",
       "      <td>Paris</td>\n",
       "      <td>234567</td>\n",
       "      <td>skincare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ikl</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>786543</td>\n",
       "      <td>makeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserID       Region  ProductID ProductTag\n",
       "0    abc     New York     879652       tech\n",
       "1    bde       London     345871    fashion\n",
       "2    sed        Tokyo     998743       tech\n",
       "3    sdj        Paris     234567   skincare\n",
       "4    ikl  Los Angeles     786543     makeup"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('CustomData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad39b76e",
   "metadata": {},
   "source": [
    "# GroupBy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1b5ca654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   UserID   ProductTag  Count\n",
      "0     abc      camping      1\n",
      "1     abc     skincare      1\n",
      "2     abc         tech      1\n",
      "3     ahj         pets      1\n",
      "4     ahj      watches      1\n",
      "5     ajk      outdoor      1\n",
      "6     aub   automotive      1\n",
      "7     aub       travel      1\n",
      "8     bde        books      1\n",
      "9     bde      fashion      1\n",
      "10    bhu  photography      1\n",
      "11    def  accessories      1\n",
      "12    hmu       health      1\n",
      "13    hmu         toys      1\n",
      "14    ihk  photography      1\n",
      "15    ikl      fashion      1\n",
      "16    ikl      fitness      1\n",
      "17    ikl      gadgets      1\n",
      "18    ikl       gaming      1\n",
      "19    ikl       makeup      1\n",
      "20    imo      outdoor      1\n",
      "21    imo       sports      1\n",
      "22    inn       hiking      1\n",
      "23    inn        music      1\n",
      "24    inn   stationery      1\n",
      "25    mno  electronics      1\n",
      "26    mno       health      1\n",
      "27    okj   automotive      1\n",
      "28    okj  kitchenware      2\n",
      "29    okl       travel      1\n",
      "30    olk      jewelry      1\n",
      "31    pqr       beauty      1\n",
      "32    qts    gardening      1\n",
      "33    res        craft      1\n",
      "34    rty         baby      1\n",
      "35    sdj        music      1\n",
      "36    sdj     skincare      1\n",
      "37    sdk          art      1\n",
      "38    sdk       beauty      1\n",
      "39    sed  electronics      1\n",
      "40    sed         tech      1\n",
      "41    sgg        craft      1\n",
      "42    shd         baby      1\n",
      "43    shd         food      1\n",
      "44    tyu          diy      1\n",
      "45    ukl         toys      1\n",
      "46    uuh      camping      1\n",
      "47    uyt       drinks      2\n"
     ]
    }
   ],
   "source": [
    "# Group distinct users with the same product tag\n",
    "grouped = df.groupby(['UserID', 'ProductTag']).size().reset_index(name='Count')\n",
    "# Display the grouped data\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3da9ac9a",
   "metadata": {},
   "source": [
    "# Similarity using FastText"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4bda8a",
   "metadata": {},
   "source": [
    "FastText learns to understand the meaning of words by looking at how they are used in different contexts. It can group or categorize text based on its content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1de00fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar group: ['tech', 'toys', 'gaming', 'kitchenware', 'sports', 'accessories']\n",
      "Similar group: ['fashion', 'outdoor', 'baby', 'art', 'health', 'music']\n",
      "Similar group: ['skincare', 'photography', 'kitchenware', 'makeup', 'gardening', 'books']\n",
      "Similar group: ['makeup', 'health', 'stationery', 'skincare', 'art', 'gaming']\n",
      "Similar group: ['electronics', 'music', 'outdoor', 'food', 'watches', 'travel']\n",
      "Similar group: ['beauty', 'drinks', 'music', 'gardening', 'camping', 'hiking']\n",
      "Similar group: ['accessories', 'camping', 'gardening', 'diy', 'drinks', 'hiking']\n",
      "Similar group: ['gadgets', 'craft', 'sports', 'fitness', 'music', 'pets']\n",
      "Similar group: ['outdoor', 'music', 'fashion', 'kitchenware', 'gardening', 'baby']\n",
      "Similar group: ['sports', 'pets', 'automotive', 'gadgets', 'toys', 'music']\n",
      "Similar group: ['health', 'gardening', 'food', 'hiking', 'art', 'makeup']\n",
      "Similar group: ['fitness', 'stationery', 'automotive', 'gadgets', 'music', 'sports']\n",
      "Similar group: ['toys', 'diy', 'tech', 'sports', 'outdoor', 'automotive']\n",
      "Similar group: ['books', 'drinks', 'diy', 'stationery', 'toys', 'sports']\n",
      "Similar group: ['kitchenware', 'outdoor', 'watches', 'gaming', 'skincare', 'gadgets']\n",
      "Similar group: ['jewelry', 'stationery', 'music', 'hiking', 'automotive', 'diy']\n",
      "Similar group: ['watches', 'camping', 'music', 'kitchenware', 'jewelry', 'electronics']\n",
      "Similar group: ['automotive', 'sports', 'jewelry', 'fitness', 'toys', 'craft']\n",
      "Similar group: ['pets', 'sports', 'photography', 'gadgets', 'hiking', 'gardening']\n",
      "Similar group: ['travel', 'makeup', 'gadgets', 'electronics', 'beauty', 'health']\n",
      "Similar group: ['gaming', 'drinks', 'craft', 'camping', 'stationery', 'art']\n",
      "Similar group: ['music', 'electronics', 'outdoor', 'jewelry', 'stationery', 'photography']\n",
      "Similar group: ['art', 'craft', 'fashion', 'health', 'gaming', 'toys']\n",
      "Similar group: ['photography', 'pets', 'skincare', 'music', 'fashion', 'outdoor']\n",
      "Similar group: ['diy', 'camping', 'drinks', 'books', 'hiking', 'toys']\n",
      "Similar group: ['craft', 'gadgets', 'art', 'gaming', 'drinks', 'jewelry']\n",
      "Similar group: ['stationery', 'jewelry', 'music', 'gaming', 'fitness', 'books']\n",
      "Similar group: ['baby', 'camping', 'fashion', 'food', 'outdoor', 'pets']\n",
      "Similar group: ['food', 'health', 'baby', 'art', 'electronics', 'music']\n",
      "Similar group: ['drinks', 'diy', 'books', 'hiking', 'gaming', 'camping']\n",
      "Similar group: ['gardening', 'health', 'outdoor', 'camping', 'hiking', 'beauty']\n",
      "Similar group: ['camping', 'diy', 'baby', 'accessories', 'watches', 'drinks']\n",
      "Similar group: ['hiking', 'drinks', 'jewelry', 'diy', 'health', 'gardening']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "# Train FastText model on product tags\n",
    "model = FastText(sentences=[product_tags], min_count=1, vector_size=100, window=5, sg=1)\n",
    "\n",
    "# Function to find similar product tags based on FastText embeddings\n",
    "def find_similar_tags(tags):\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "    return similar_groups\n",
    "\n",
    "# Find similar product tags\n",
    "similar_groups = find_similar_tags(product_tags)\n",
    "\n",
    "# Display similar groups\n",
    "for group in similar_groups:\n",
    "    print(\"Similar group:\", group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9148185",
   "metadata": {},
   "source": [
    "# Similarity using Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f53ce7aa",
   "metadata": {},
   "source": [
    "It captures the contextual meaning of words by considering the words that frequently appear nearby in a given text corpus.\n",
    "Words that occur in similar contexts are represented by vectors that are close to each other in the vector space."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c38e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned group: ['tech', 'toys', 'beauty', 'diy', 'food', 'watches']\n",
      "Assigned group: ['fashion', 'fitness', 'gardening', 'photography', 'books', 'music']\n",
      "Assigned group: ['skincare', 'camping', 'pets', 'books', 'makeup', 'photography']\n",
      "Assigned group: ['electronics', 'baby', 'craft', 'music', 'books', 'jewelry']\n",
      "Assigned group: ['makeup', 'photography', 'watches', 'kitchenware', 'skincare', 'craft']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "\n",
    "model = Word2Vec([product_tags], min_count=1, vector_size=100)  # Adjust parameters as needed\n",
    "\n",
    "def find_similar_tags(tags, max_groups=5):  # Specify the maximum number of groups\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "            if len(similar_groups) >= max_groups:  # Check if the maximum number of groups is reached\n",
    "                break\n",
    "    \n",
    "    # Create a dictionary to map each tag to its corresponding group\n",
    "    tag_to_group = defaultdict(list)\n",
    "    for group in similar_groups:\n",
    "        for tag in group:\n",
    "            tag_to_group[tag].append(group)\n",
    "    \n",
    "    # Assign each tag to the most similar group\n",
    "    assigned_groups = []\n",
    "    for tag in tags:\n",
    "        if tag_to_group[tag]:  # Check if the list of groups for the tag is not empty\n",
    "            most_similar_group = max(tag_to_group[tag], key=lambda x: len(set(x) & set(tags)))\n",
    "            if most_similar_group not in assigned_groups:\n",
    "                assigned_groups.append(most_similar_group)\n",
    "    \n",
    "    return assigned_groups\n",
    "\n",
    "assigned_groups = find_similar_tags(product_tags)\n",
    "\n",
    "for group in assigned_groups:\n",
    "    print(\"Assigned group:\", group)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "deb0f762",
   "metadata": {},
   "source": [
    "The only difference between Word2Vec and FastText lies in handling of out-of-vocabulary words. \n",
    "Since, this application will only have frequently used words, Word2Vec is a better choice because it performs better with words as opposed to FastText which performs better with sub-word information like misspellings, sentiment analysis etc."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4df0e6",
   "metadata": {},
   "source": [
    "# Assigning Users to Groups Generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a0e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: ['abc', 'sed', 'pqr', 'sdk', 'hmu', 'ukl', 'ahj', 'tyu', 'shd']\n",
      "Group 1: ['bde', 'bde', 'sdj', 'ikl', 'ikl', 'inn', 'ihk', 'bhu', 'qts']\n",
      "Group 2: ['abc', 'abc', 'bde', 'sdj', 'ikl', 'ahj', 'ihk', 'bhu', 'uuh']\n",
      "Group 3: ['bde', 'sed', 'sdj', 'mno', 'olk', 'inn', 'sgg', 'res', 'rty', 'shd']\n",
      "Group 4: ['abc', 'sdj', 'ikl', 'okj', 'okj', 'ahj', 'ihk', 'bhu', 'sgg', 'res']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming df contains user data with columns UserID and ProductTag\n",
    "# and assigned_groups contains the assigned groups as obtained previously\n",
    "\n",
    "# Create a dictionary to map each product tag to its corresponding group(s)\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(list)\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].append(user)\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54bad23",
   "metadata": {},
   "source": [
    "# Generating New Data from Existing Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d34ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize empty lists\n",
    "user_ids = []\n",
    "product_tags = []\n",
    "city_names = []\n",
    "product_ids = []\n",
    "\n",
    "# Generate 15 data points for each field\n",
    "\n",
    "user_ids.extend([''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=3)) for _ in range(15)])\n",
    "product_tags.extend(random.choices(['tech', 'fashion', 'skincare', 'makeup', 'electronics', 'beauty', 'gadgets', 'outdoor', 'sports', 'health', 'fitness', 'toys', 'books', 'kitchenware', 'jewelry', 'watches', 'automotive', 'pets', 'travel', 'gaming', 'music', 'art', 'photography', 'diy', 'craft', 'stationery', 'baby', 'food', 'drinks', 'gardening', 'camping'], k=15))\n",
    "city_names.extend(random.choices(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville', 'San Francisco', 'Indianapolis', 'Columbus', 'Fort Worth', 'Charlotte', 'Seattle', 'Denver', 'Washington', 'Boston', 'El Paso', 'Detroit', 'Nashville', 'Portland', 'Memphis', 'Oklahoma City'], k=15))\n",
    "product_ids.extend([str(random.randint(100000, 999999)) for _ in range(15)])\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'UserID': user_ids,\n",
    "    'ProductTag': product_tags,\n",
    "    'Region': city_names,\n",
    "    'ProductID': product_ids\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Read existing CustomData.csv file\n",
    "existing_data = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Concatenate existing data with new data\n",
    "updated_data = pd.concat([existing_data, df])\n",
    "\n",
    "# Write updated DataFrame to CSV\n",
    "updated_data.to_csv('CustomData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "280b773f",
   "metadata": {},
   "source": [
    "# Dynamic Allocation of Groups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ce7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: ['sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ahj', 'sgh', 'sed', 'ukl', 'ixu', 'abc', 'hmu']\n",
      "Group 1: ['hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ikl', 'bhu', 'tny', 'qts']\n",
      "Group 2: ['uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bhu', 'abc']\n",
      "Group 3: ['hqd', 'shd', 'bde', 'sdj', 'wjq', 'inn', 'ldh', 'olk', 'sed', 'mno', 'sgg', 'res', 'rty', 'tny', 'pmj']\n",
      "Group 4: ['okj', 'ihk', 'sdj', 'ikl', 'ahj', 'bhu', 'sgg', 'res', 'abc', 'pmj', 'pgk']\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('CustomData.csv')\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(set)  # Changed to set to ensure distinct values\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].add(user)  # Use add instead of append for sets\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {list(users)}\")  # Convert set to list for printing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3693963",
   "metadata": {},
   "source": [
    "# Handling New User"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5662face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User(s) from same region:  ['okj']\n",
      "Group 0: {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ahj', 'sgh', 'sed', 'ukl', 'ixu', 'abc', 'hmu'}\n",
      "Group 1: {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ikl', 'bhu', 'tny', 'qts'}\n",
      "Group 2: {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bhu', 'abc'}\n",
      "Group 3: {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'inn', 'ldh', 'olk', 'sed', 'mno', 'sgg', 'res', 'rty', 'tny', 'pmj'}\n",
      "Group 4: {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bhu', 'sgg', 'res', 'abc', 'pmj', 'pgk'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Define the new user's region\n",
    "new_user_region = 'Kolkata'\n",
    "\n",
    "# Find the group with the maximum users\n",
    "group_with_max_users = max(groups_users, key=lambda x: len(groups_users[x]))\n",
    "\n",
    "# Find users from the same region as the new user\n",
    "users_from_same_region = [user for user, region in zip(df['UserID'], df['Region']) if region == new_user_region]\n",
    "if len(users_from_same_region)>0:\n",
    "    print('User(s) from same region: ',users_from_same_region)\n",
    "# Add the new user 'xyz' to the group with the maximum users\n",
    "group_with_max_users_users = set(groups_users[group_with_max_users])\n",
    "group_with_max_users_users.add('xyz')\n",
    "groups_users[group_with_max_users] = group_with_max_users_users\n",
    "\n",
    "# If users from the same region exist, add 'xyz' to the corresponding group\n",
    "if users_from_same_region:\n",
    "    user_from_same_region = users_from_same_region[0]  # Assuming only one user from the same region\n",
    "    group_with_same_region = next((group for group, users in groups_users.items() if user_from_same_region in users), None)\n",
    "    if group_with_same_region is not None:\n",
    "        group_with_same_region_users = set(groups_users[group_with_same_region])\n",
    "        group_with_same_region_users.add('xyz')\n",
    "        groups_users[group_with_same_region] = group_with_same_region_users\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "640871ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Assigned_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...</td>\n",
       "      <td>[tech, toys, beauty, diy, food, watches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...</td>\n",
       "      <td>[fashion, fitness, gardening, photography, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}</td>\n",
       "      <td>[skincare, camping, pets, books, makeup, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...</td>\n",
       "      <td>[electronics, baby, craft, music, books, jewelry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...</td>\n",
       "      <td>[makeup, photography, watches, kitchenware, sk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Users  \\\n",
       "0  {sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...   \n",
       "1  {hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...   \n",
       "2           {uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}   \n",
       "3  {hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...   \n",
       "4  {okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...   \n",
       "\n",
       "                                      Assigned_Group  \n",
       "0           [tech, toys, beauty, diy, food, watches]  \n",
       "1  [fashion, fitness, gardening, photography, boo...  \n",
       "2  [skincare, camping, pets, books, makeup, photo...  \n",
       "3  [electronics, baby, craft, music, books, jewelry]  \n",
       "4  [makeup, photography, watches, kitchenware, sk...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups_users= pd.DataFrame(sorted_groups_users, columns=['Group', 'Users'])\n",
    "df_groups_users= df_groups_users.drop(columns=['Group'])\n",
    "df_groups_users['Assigned_Group'] = [assigned_groups[group] for group, _ in sorted_groups_users]\n",
    "df_groups_users.to_csv('Output.csv', index=False)\n",
    "df_groups_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bd56c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Assigned_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...</td>\n",
       "      <td>[tech, toys, beauty, diy, food, watches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...</td>\n",
       "      <td>[fashion, fitness, gardening, photography, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}</td>\n",
       "      <td>[skincare, camping, pets, books, makeup, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...</td>\n",
       "      <td>[electronics, baby, craft, music, books, jewelry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...</td>\n",
       "      <td>[makeup, photography, watches, kitchenware, sk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Users  \\\n",
       "0  {sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...   \n",
       "1  {hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...   \n",
       "2           {uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}   \n",
       "3  {hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...   \n",
       "4  {okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...   \n",
       "\n",
       "                                      Assigned_Group  \n",
       "0           [tech, toys, beauty, diy, food, watches]  \n",
       "1  [fashion, fitness, gardening, photography, boo...  \n",
       "2  [skincare, camping, pets, books, makeup, photo...  \n",
       "3  [electronics, baby, craft, music, books, jewelry]  \n",
       "4  [makeup, photography, watches, kitchenware, sk...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups_users.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fce97742",
   "metadata": {},
   "source": [
    "# Encryption"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e79f94f1",
   "metadata": {},
   "source": [
    "# DES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3017e66a",
   "metadata": {},
   "source": [
    "The Data Encryption Standard (DES) is a symmetric-key block cipher algorithm that operates on 64-bit blocks of data. It uses a 56-bit key to perform a series of permutations and substitutions, including initial and final permutations, 16 rounds of Feistel function iterations, and key schedule generation, to encrypt and decrypt data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2470ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import DES\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = 8 - (len(data) % 8)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using DES\n",
    "def encrypt_data(key, data):\n",
    "    cipher = DES.new(key, DES.MODE_ECB)\n",
    "    padded_data = pad(data)\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data)\n",
    "\n",
    "# Decrypt data using DES\n",
    "def decrypt_data(key, data):\n",
    "    cipher = DES.new(key, DES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data))\n",
    "    return unpad(decrypted_data)\n",
    "\n",
    "# Generate a random 8-byte key for DES\n",
    "def generate_des_key():\n",
    "    return get_random_bytes(8)\n",
    "\n",
    "# Generate DES key\n",
    "des_key = generate_des_key()\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Encrypt each cell in the DataFrame and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data(des_key, str(value).encode()).decode())\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data(des_key, value).decode())\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6080c5fe",
   "metadata": {},
   "source": [
    "# AES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10c1e14b",
   "metadata": {},
   "source": [
    "The Advanced Encryption Standard (AES) is a symmetric-key block cipher algorithm widely used for encryption and decryption. It operates on data blocks of 128 bits and supports key sizes of 128, 192, or 256 bits. AES employs a substitution-permutation network (SPN) structure, including key expansion, multiple rounds of substitution and permutation operations, and a final mixing operation, to provide strong confidentiality and security. AES is considered highly secure and is commonly used in various applications, including data encryption, secure communication protocols, and cryptographic protocols."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dca1bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = AES.block_size - (len(data) % AES.block_size)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using AES\n",
    "def encrypt_data(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    padded_data = pad(data.encode())\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data).decode()\n",
    "\n",
    "# Decrypt data using AES\n",
    "def decrypt_data(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data.encode()))\n",
    "    return unpad(decrypted_data).decode()\n",
    "\n",
    "# Generate a random 16-byte key for AES (128 bits)\n",
    "def generate_aes_key():\n",
    "    return get_random_bytes(16)\n",
    "\n",
    "# Generate AES key\n",
    "aes_key = generate_aes_key()\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Encrypt each cell in the DataFrame and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data(aes_key, str(value)))\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data(aes_key, str(value)))\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac644e81",
   "metadata": {},
   "source": [
    "# Combining AES and ECC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9629d4c",
   "metadata": {},
   "source": [
    "Data encrypted using AES; key of AES encrypted using ECC. Similarly, key decrypted using ECC and data decrypted using AES"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9aca6cf1",
   "metadata": {},
   "source": [
    "Elliptic Curve Cryptography (ECC) is a public-key cryptography technique based on the algebraic structure of elliptic curves over finite fields. It relies on the difficulty of the elliptic curve discrete logarithm problem (ECDLP) for its security. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e24ec3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted with AES and ECC and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.PublicKey import ECC\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = AES.block_size - (len(data) % AES.block_size)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using AES\n",
    "def encrypt_data_aes(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    padded_data = pad(data.encode())\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data).decode()\n",
    "\n",
    "# Decrypt data using AES\n",
    "def decrypt_data_aes(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data.encode()))\n",
    "    return unpad(decrypted_data).decode()\n",
    "\n",
    "# Generate a random 16-byte key for AES (128 bits)\n",
    "def generate_aes_key():\n",
    "    return get_random_bytes(16)\n",
    "\n",
    "# Generate ECC key pair\n",
    "def generate_ecc_key_pair():\n",
    "    key = ECC.generate(curve='P-256')\n",
    "    private_key = key.export_key(format='PEM')\n",
    "    public_key = key.public_key().export_key(format='PEM')\n",
    "    return private_key, public_key\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Generate AES key\n",
    "aes_key = generate_aes_key()\n",
    "\n",
    "# Generate ECC key pair\n",
    "private_key, public_key = generate_ecc_key_pair()\n",
    "\n",
    "# Encrypt each cell in the DataFrame using AES and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data_aes(aes_key, str(value)))\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted with AES and ECC and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data_aes(aes_key, value))\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
