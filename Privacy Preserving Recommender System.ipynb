{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2c4eacad",
   "metadata": {},
   "source": [
    "# Dynamic Segmentation of Users in a Recommender System"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "de4280ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>UserID</th>\n",
       "      <th>Region</th>\n",
       "      <th>ProductID</th>\n",
       "      <th>ProductTag</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>abc</td>\n",
       "      <td>New York</td>\n",
       "      <td>879652</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>bde</td>\n",
       "      <td>London</td>\n",
       "      <td>345871</td>\n",
       "      <td>fashion</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>sed</td>\n",
       "      <td>Tokyo</td>\n",
       "      <td>998743</td>\n",
       "      <td>tech</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sdj</td>\n",
       "      <td>Paris</td>\n",
       "      <td>234567</td>\n",
       "      <td>skincare</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>ikl</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>786543</td>\n",
       "      <td>makeup</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  UserID       Region  ProductID ProductTag\n",
       "0    abc     New York     879652       tech\n",
       "1    bde       London     345871    fashion\n",
       "2    sed        Tokyo     998743       tech\n",
       "3    sdj        Paris     234567   skincare\n",
       "4    ikl  Los Angeles     786543     makeup"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "df=pd.read_csv('CustomData.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1b5ca654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     ProductTag UserID  Count\n",
      "0   accessories    def      1\n",
      "1           art    sdk      1\n",
      "2    automotive    aub      1\n",
      "3    automotive    okj      1\n",
      "4          baby    rty      1\n",
      "5          baby    shd      1\n",
      "6        beauty    pqr      1\n",
      "7        beauty    sdk      1\n",
      "8         books    bde      1\n",
      "9       camping    abc      1\n",
      "10      camping    uuh      1\n",
      "11        craft    res      1\n",
      "12        craft    sgg      1\n",
      "13          diy    tyu      1\n",
      "14       drinks    uyt      2\n",
      "15  electronics    mno      1\n",
      "16  electronics    sed      1\n",
      "17      fashion    bde      1\n",
      "18      fashion    ikl      1\n",
      "19      fitness    ikl      1\n",
      "20         food    shd      1\n",
      "21      gadgets    ikl      1\n",
      "22       gaming    ikl      1\n",
      "23    gardening    qts      1\n",
      "24       health    hmu      1\n",
      "25       health    mno      1\n",
      "26       hiking    inn      1\n",
      "27      jewelry    olk      1\n",
      "28  kitchenware    okj      2\n",
      "29       makeup    ikl      1\n",
      "30        music    inn      1\n",
      "31        music    sdj      1\n",
      "32      outdoor    ajk      1\n",
      "33      outdoor    imo      1\n",
      "34         pets    ahj      1\n",
      "35  photography    bhu      1\n",
      "36  photography    ihk      1\n",
      "37     skincare    abc      1\n",
      "38     skincare    sdj      1\n",
      "39       sports    imo      1\n",
      "40   stationery    inn      1\n",
      "41         tech    abc      1\n",
      "42         tech    sed      1\n",
      "43         toys    hmu      1\n",
      "44         toys    ukl      1\n",
      "45       travel    aub      1\n",
      "46       travel    okl      1\n",
      "47      watches    ahj      1\n"
     ]
    }
   ],
   "source": [
    "# Group distinct users with the same product tag\n",
    "grouped = df.groupby(['ProductTag', 'UserID']).size().reset_index(name='Count')\n",
    "# Display the grouped data\n",
    "print(grouped)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1de00fd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Similar group: ['tech', 'toys', 'gaming', 'kitchenware', 'sports', 'accessories']\n",
      "Similar group: ['fashion', 'outdoor', 'baby', 'art', 'health', 'music']\n",
      "Similar group: ['skincare', 'photography', 'kitchenware', 'makeup', 'gardening', 'books']\n",
      "Similar group: ['makeup', 'health', 'stationery', 'skincare', 'art', 'gaming']\n",
      "Similar group: ['electronics', 'music', 'outdoor', 'food', 'watches', 'travel']\n",
      "Similar group: ['beauty', 'drinks', 'music', 'gardening', 'camping', 'hiking']\n",
      "Similar group: ['accessories', 'camping', 'gardening', 'diy', 'drinks', 'hiking']\n",
      "Similar group: ['gadgets', 'craft', 'sports', 'fitness', 'music', 'pets']\n",
      "Similar group: ['outdoor', 'music', 'fashion', 'kitchenware', 'gardening', 'baby']\n",
      "Similar group: ['sports', 'pets', 'automotive', 'gadgets', 'toys', 'music']\n",
      "Similar group: ['health', 'gardening', 'food', 'hiking', 'art', 'makeup']\n",
      "Similar group: ['fitness', 'stationery', 'automotive', 'gadgets', 'music', 'sports']\n",
      "Similar group: ['toys', 'diy', 'tech', 'sports', 'outdoor', 'automotive']\n",
      "Similar group: ['books', 'drinks', 'diy', 'stationery', 'toys', 'sports']\n",
      "Similar group: ['kitchenware', 'outdoor', 'watches', 'gaming', 'skincare', 'gadgets']\n",
      "Similar group: ['jewelry', 'stationery', 'music', 'hiking', 'automotive', 'diy']\n",
      "Similar group: ['watches', 'camping', 'music', 'kitchenware', 'jewelry', 'electronics']\n",
      "Similar group: ['automotive', 'sports', 'jewelry', 'fitness', 'toys', 'craft']\n",
      "Similar group: ['pets', 'sports', 'photography', 'gadgets', 'hiking', 'gardening']\n",
      "Similar group: ['travel', 'makeup', 'gadgets', 'electronics', 'beauty', 'health']\n",
      "Similar group: ['gaming', 'drinks', 'craft', 'camping', 'stationery', 'art']\n",
      "Similar group: ['music', 'electronics', 'outdoor', 'jewelry', 'stationery', 'photography']\n",
      "Similar group: ['art', 'craft', 'fashion', 'health', 'gaming', 'toys']\n",
      "Similar group: ['photography', 'pets', 'skincare', 'music', 'fashion', 'outdoor']\n",
      "Similar group: ['diy', 'camping', 'drinks', 'books', 'hiking', 'toys']\n",
      "Similar group: ['craft', 'gadgets', 'art', 'gaming', 'drinks', 'jewelry']\n",
      "Similar group: ['stationery', 'jewelry', 'music', 'gaming', 'fitness', 'books']\n",
      "Similar group: ['baby', 'camping', 'fashion', 'food', 'outdoor', 'pets']\n",
      "Similar group: ['food', 'health', 'baby', 'art', 'electronics', 'music']\n",
      "Similar group: ['drinks', 'diy', 'books', 'hiking', 'gaming', 'camping']\n",
      "Similar group: ['gardening', 'health', 'outdoor', 'camping', 'hiking', 'beauty']\n",
      "Similar group: ['camping', 'diy', 'baby', 'accessories', 'watches', 'drinks']\n",
      "Similar group: ['hiking', 'drinks', 'jewelry', 'diy', 'health', 'gardening']\n"
     ]
    }
   ],
   "source": [
    "from gensim.models import FastText\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "# Train FastText model on product tags\n",
    "model = FastText(sentences=[product_tags], min_count=1, vector_size=100, window=5, sg=1)\n",
    "\n",
    "# Function to find similar product tags based on FastText embeddings\n",
    "def find_similar_tags(tags):\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "    return similar_groups\n",
    "\n",
    "# Find similar product tags\n",
    "similar_groups = find_similar_tags(product_tags)\n",
    "\n",
    "# Display similar groups\n",
    "for group in similar_groups:\n",
    "    print(\"Similar group:\", group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b4c38e76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Assigned group: ['tech', 'toys', 'beauty', 'diy', 'food', 'watches']\n",
      "Assigned group: ['fashion', 'fitness', 'gardening', 'photography', 'books', 'music']\n",
      "Assigned group: ['skincare', 'camping', 'pets', 'books', 'makeup', 'photography']\n",
      "Assigned group: ['electronics', 'baby', 'craft', 'music', 'books', 'jewelry']\n",
      "Assigned group: ['makeup', 'photography', 'watches', 'kitchenware', 'skincare', 'craft']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "product_tags = df['ProductTag'].tolist()\n",
    "\n",
    "model = Word2Vec([product_tags], min_count=1, vector_size=100)  # Adjust parameters as needed\n",
    "\n",
    "def find_similar_tags(tags, max_groups=5):  # Specify the maximum number of groups\n",
    "    similar_groups = []\n",
    "    for tag in tags:\n",
    "        similar_tags = model.wv.most_similar(tag, topn=5)  # Get top 5 most similar tags\n",
    "        similar_group = [tag] + [similar_tag[0] for similar_tag in similar_tags]\n",
    "        if len(similar_group) > 1 and similar_group not in similar_groups:\n",
    "            similar_groups.append(similar_group)\n",
    "            if len(similar_groups) >= max_groups:  # Check if the maximum number of groups is reached\n",
    "                break\n",
    "    \n",
    "    # Create a dictionary to map each tag to its corresponding group\n",
    "    tag_to_group = defaultdict(list)\n",
    "    for group in similar_groups:\n",
    "        for tag in group:\n",
    "            tag_to_group[tag].append(group)\n",
    "    \n",
    "    # Assign each tag to the most similar group\n",
    "    assigned_groups = []\n",
    "    for tag in tags:\n",
    "        if tag_to_group[tag]:  # Check if the list of groups for the tag is not empty\n",
    "            most_similar_group = max(tag_to_group[tag], key=lambda x: len(set(x) & set(tags)))\n",
    "            if most_similar_group not in assigned_groups:\n",
    "                assigned_groups.append(most_similar_group)\n",
    "    \n",
    "    return assigned_groups\n",
    "\n",
    "assigned_groups = find_similar_tags(product_tags)\n",
    "\n",
    "for group in assigned_groups:\n",
    "    print(\"Assigned group:\", group)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46a0e4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: ['abc', 'sed', 'pqr', 'sdk', 'hmu', 'ukl', 'ahj', 'tyu', 'shd']\n",
      "Group 1: ['bde', 'bde', 'sdj', 'ikl', 'ikl', 'inn', 'ihk', 'bhu', 'qts']\n",
      "Group 2: ['abc', 'abc', 'bde', 'sdj', 'ikl', 'ahj', 'ihk', 'bhu', 'uuh']\n",
      "Group 3: ['bde', 'sed', 'sdj', 'mno', 'olk', 'inn', 'sgg', 'res', 'rty', 'shd']\n",
      "Group 4: ['abc', 'sdj', 'ikl', 'okj', 'okj', 'ahj', 'ihk', 'bhu', 'sgg', 'res']\n"
     ]
    }
   ],
   "source": [
    "from collections import defaultdict\n",
    "\n",
    "# Assuming df contains user data with columns UserID and ProductTag\n",
    "# and assigned_groups contains the assigned groups as obtained previously\n",
    "\n",
    "# Create a dictionary to map each product tag to its corresponding group(s)\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(list)\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].append(user)\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7d34ce14",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import random\n",
    "\n",
    "# Initialize empty lists\n",
    "user_ids = []\n",
    "product_tags = []\n",
    "city_names = []\n",
    "product_ids = []\n",
    "\n",
    "# Generate 15 data points for each field\n",
    "\n",
    "user_ids.extend([''.join(random.choices('abcdefghijklmnopqrstuvwxyz', k=3)) for _ in range(15)])\n",
    "product_tags.extend(random.choices(['tech', 'fashion', 'skincare', 'makeup', 'electronics', 'beauty', 'gadgets', 'outdoor', 'sports', 'health', 'fitness', 'toys', 'books', 'kitchenware', 'jewelry', 'watches', 'automotive', 'pets', 'travel', 'gaming', 'music', 'art', 'photography', 'diy', 'craft', 'stationery', 'baby', 'food', 'drinks', 'gardening', 'camping'], k=15))\n",
    "city_names.extend(random.choices(['New York', 'Los Angeles', 'Chicago', 'Houston', 'Phoenix', 'Philadelphia', 'San Antonio', 'San Diego', 'Dallas', 'San Jose', 'Austin', 'Jacksonville', 'San Francisco', 'Indianapolis', 'Columbus', 'Fort Worth', 'Charlotte', 'Seattle', 'Denver', 'Washington', 'Boston', 'El Paso', 'Detroit', 'Nashville', 'Portland', 'Memphis', 'Oklahoma City'], k=15))\n",
    "product_ids.extend([str(random.randint(100000, 999999)) for _ in range(15)])\n",
    "\n",
    "# Create DataFrame\n",
    "data = {\n",
    "    'UserID': user_ids,\n",
    "    'ProductTag': product_tags,\n",
    "    'Region': city_names,\n",
    "    'ProductID': product_ids\n",
    "}\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "# Read existing CustomData.csv file\n",
    "existing_data = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Concatenate existing data with new data\n",
    "updated_data = pd.concat([existing_data, df])\n",
    "\n",
    "# Write updated DataFrame to CSV\n",
    "updated_data.to_csv('CustomData.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f0ce7bf5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Group 0: ['sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ahj', 'sgh', 'sed', 'ukl', 'ixu', 'abc', 'hmu']\n",
      "Group 1: ['hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ikl', 'bhu', 'tny', 'qts']\n",
      "Group 2: ['uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bhu', 'abc']\n",
      "Group 3: ['hqd', 'shd', 'bde', 'sdj', 'wjq', 'inn', 'ldh', 'olk', 'sed', 'mno', 'sgg', 'res', 'rty', 'tny', 'pmj']\n",
      "Group 4: ['okj', 'ihk', 'sdj', 'ikl', 'ahj', 'bhu', 'sgg', 'res', 'abc', 'pmj', 'pgk']\n"
     ]
    }
   ],
   "source": [
    "df=pd.read_csv('CustomData.csv')\n",
    "tag_to_group = defaultdict(list)\n",
    "for idx, group in enumerate(assigned_groups):\n",
    "    for tag in group:\n",
    "        tag_to_group[tag].append(idx)  # Use index of the group instead of the group itself\n",
    "\n",
    "# Initialize a dictionary to store the groups each user belongs to\n",
    "user_to_groups = defaultdict(list)\n",
    "\n",
    "# Iterate through each user and assign them to groups based on their ProductTag\n",
    "for index, row in df.iterrows():\n",
    "    user_id = row['UserID']\n",
    "    product_tags = row['ProductTag'].split(',')  # Split tags if they are comma-separated\n",
    "    for tag in product_tags:\n",
    "        if tag in tag_to_group:\n",
    "            user_to_groups[user_id].extend(tag_to_group[tag])\n",
    "\n",
    "# Organize users into groups\n",
    "groups_users = defaultdict(set)  # Changed to set to ensure distinct values\n",
    "for user, groups in user_to_groups.items():\n",
    "    for group in groups:\n",
    "        groups_users[group].add(user)  # Use add instead of append for sets\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {list(users)}\")  # Convert set to list for printing\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5662face",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "User(s) from same region:  ['okj']\n",
      "Group 0: {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ahj', 'sgh', 'sed', 'ukl', 'ixu', 'abc', 'hmu'}\n",
      "Group 1: {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ikl', 'bhu', 'tny', 'qts'}\n",
      "Group 2: {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bhu', 'abc'}\n",
      "Group 3: {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'inn', 'ldh', 'olk', 'sed', 'mno', 'sgg', 'res', 'rty', 'tny', 'pmj'}\n",
      "Group 4: {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bhu', 'sgg', 'res', 'abc', 'pmj', 'pgk'}\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "\n",
    "# Load the data\n",
    "df = pd.read_csv('CustomData.csv')\n",
    "\n",
    "# Define the new user's region\n",
    "new_user_region = 'Kolkata'\n",
    "\n",
    "# Find the group with the maximum users\n",
    "group_with_max_users = max(groups_users, key=lambda x: len(groups_users[x]))\n",
    "\n",
    "# Find users from the same region as the new user\n",
    "users_from_same_region = [user for user, region in zip(df['UserID'], df['Region']) if region == new_user_region]\n",
    "if len(users_from_same_region)>0:\n",
    "    print('User(s) from same region: ',users_from_same_region)\n",
    "# Add the new user 'xyz' to the group with the maximum users\n",
    "group_with_max_users_users = set(groups_users[group_with_max_users])\n",
    "group_with_max_users_users.add('xyz')\n",
    "groups_users[group_with_max_users] = group_with_max_users_users\n",
    "\n",
    "# If users from the same region exist, add 'xyz' to the corresponding group\n",
    "if users_from_same_region:\n",
    "    user_from_same_region = users_from_same_region[0]  # Assuming only one user from the same region\n",
    "    group_with_same_region = next((group for group, users in groups_users.items() if user_from_same_region in users), None)\n",
    "    if group_with_same_region is not None:\n",
    "        group_with_same_region_users = set(groups_users[group_with_same_region])\n",
    "        group_with_same_region_users.add('xyz')\n",
    "        groups_users[group_with_same_region] = group_with_same_region_users\n",
    "\n",
    "# Sort the groups by their names\n",
    "sorted_groups_users = sorted(groups_users.items(), key=lambda x: x[0])\n",
    "\n",
    "# Print the users assigned to each group\n",
    "for group, users in sorted_groups_users:\n",
    "    print(f\"Group {group}: {users}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "640871ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Assigned_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...</td>\n",
       "      <td>[tech, toys, beauty, diy, food, watches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...</td>\n",
       "      <td>[fashion, fitness, gardening, photography, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}</td>\n",
       "      <td>[skincare, camping, pets, books, makeup, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...</td>\n",
       "      <td>[electronics, baby, craft, music, books, jewelry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...</td>\n",
       "      <td>[makeup, photography, watches, kitchenware, sk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Users  \\\n",
       "0  {sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...   \n",
       "1  {hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...   \n",
       "2           {uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}   \n",
       "3  {hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...   \n",
       "4  {okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...   \n",
       "\n",
       "                                      Assigned_Group  \n",
       "0           [tech, toys, beauty, diy, food, watches]  \n",
       "1  [fashion, fitness, gardening, photography, boo...  \n",
       "2  [skincare, camping, pets, books, makeup, photo...  \n",
       "3  [electronics, baby, craft, music, books, jewelry]  \n",
       "4  [makeup, photography, watches, kitchenware, sk...  "
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups_users= pd.DataFrame(sorted_groups_users, columns=['Group', 'Users'])\n",
    "df_groups_users= df_groups_users.drop(columns=['Group'])\n",
    "df_groups_users['Assigned_Group'] = [assigned_groups[group] for group, _ in sorted_groups_users]\n",
    "df_groups_users.to_csv('Output.csv', index=False)\n",
    "df_groups_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "f2470ea4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import DES\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = 8 - (len(data) % 8)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using DES\n",
    "def encrypt_data(key, data):\n",
    "    cipher = DES.new(key, DES.MODE_ECB)\n",
    "    padded_data = pad(data)\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data)\n",
    "\n",
    "# Decrypt data using DES\n",
    "def decrypt_data(key, data):\n",
    "    cipher = DES.new(key, DES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data))\n",
    "    return unpad(decrypted_data)\n",
    "\n",
    "# Generate a random 8-byte key for DES\n",
    "def generate_des_key():\n",
    "    return get_random_bytes(8)\n",
    "\n",
    "# Generate DES key\n",
    "des_key = generate_des_key()\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Encrypt each cell in the DataFrame and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data(des_key, str(value).encode()).decode())\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data(des_key, value).decode())\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6bd56c34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Users</th>\n",
       "      <th>Assigned_Group</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>{sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...</td>\n",
       "      <td>[tech, toys, beauty, diy, food, watches]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>{hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...</td>\n",
       "      <td>[fashion, fitness, gardening, photography, boo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>{uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}</td>\n",
       "      <td>[skincare, camping, pets, books, makeup, photo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>{hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...</td>\n",
       "      <td>[electronics, baby, craft, music, books, jewelry]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>{okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...</td>\n",
       "      <td>[makeup, photography, watches, kitchenware, sk...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Users  \\\n",
       "0  {sdk, shd, pqr, tyu, szz, xps, ahj, sgh, sed, ...   \n",
       "1  {hqd, ihk, bde, sdj, gbf, inn, ikl, bhu, tny, ...   \n",
       "2           {uuh, ihk, bde, sdj, ikl, ahj, bhu, abc}   \n",
       "3  {hqd, shd, xyz, bde, sdj, wjq, inn, ldh, olk, ...   \n",
       "4  {okj, ihk, xyz, sdj, ikl, ahj, bhu, sgg, res, ...   \n",
       "\n",
       "                                      Assigned_Group  \n",
       "0           [tech, toys, beauty, diy, food, watches]  \n",
       "1  [fashion, fitness, gardening, photography, boo...  \n",
       "2  [skincare, camping, pets, books, makeup, photo...  \n",
       "3  [electronics, baby, craft, music, books, jewelry]  \n",
       "4  [makeup, photography, watches, kitchenware, sk...  "
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_groups_users.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "dca1bd40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = AES.block_size - (len(data) % AES.block_size)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using AES\n",
    "def encrypt_data(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    padded_data = pad(data.encode())\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data).decode()\n",
    "\n",
    "# Decrypt data using AES\n",
    "def decrypt_data(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data.encode()))\n",
    "    return unpad(decrypted_data).decode()\n",
    "\n",
    "# Generate a random 16-byte key for AES (128 bits)\n",
    "def generate_aes_key():\n",
    "    return get_random_bytes(16)\n",
    "\n",
    "# Generate AES key\n",
    "aes_key = generate_aes_key()\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Encrypt each cell in the DataFrame and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data(aes_key, str(value)))\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data(aes_key, str(value)))\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "e24ec3c9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data encrypted with AES and ECC and saved to Encrypted_GroupedUsers.xlsx\n",
      "Data decrypted:\n",
      "                                               Users  \\\n",
      "0  {'sdk', 'shd', 'pqr', 'tyu', 'szz', 'xps', 'ah...   \n",
      "1  {'hqd', 'ihk', 'bde', 'sdj', 'gbf', 'inn', 'ik...   \n",
      "2  {'uuh', 'ihk', 'bde', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "3  {'hqd', 'shd', 'xyz', 'bde', 'sdj', 'wjq', 'in...   \n",
      "4  {'okj', 'ihk', 'xyz', 'sdj', 'ikl', 'ahj', 'bh...   \n",
      "\n",
      "                                      Assigned_Group  \n",
      "0  ['tech', 'toys', 'beauty', 'diy', 'food', 'wat...  \n",
      "1  ['fashion', 'fitness', 'gardening', 'photograp...  \n",
      "2  ['skincare', 'camping', 'pets', 'books', 'make...  \n",
      "3  ['electronics', 'baby', 'craft', 'music', 'boo...  \n",
      "4  ['makeup', 'photography', 'watches', 'kitchenw...  \n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from Crypto.Cipher import AES\n",
    "from Crypto.PublicKey import ECC\n",
    "from Crypto.Random import get_random_bytes\n",
    "import base64\n",
    "\n",
    "# Padding for the input data\n",
    "def pad(data):\n",
    "    length = AES.block_size - (len(data) % AES.block_size)\n",
    "    return data + bytes([length]) * length\n",
    "\n",
    "# Unpad the data\n",
    "def unpad(data):\n",
    "    return data[:-data[-1]]\n",
    "\n",
    "# Encrypt data using AES\n",
    "def encrypt_data_aes(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    padded_data = pad(data.encode())\n",
    "    encrypted_data = cipher.encrypt(padded_data)\n",
    "    return base64.b64encode(encrypted_data).decode()\n",
    "\n",
    "# Decrypt data using AES\n",
    "def decrypt_data_aes(key, data):\n",
    "    cipher = AES.new(key, AES.MODE_ECB)\n",
    "    decrypted_data = cipher.decrypt(base64.b64decode(data.encode()))\n",
    "    return unpad(decrypted_data).decode()\n",
    "\n",
    "# Generate a random 16-byte key for AES (128 bits)\n",
    "def generate_aes_key():\n",
    "    return get_random_bytes(16)\n",
    "\n",
    "# Generate ECC key pair\n",
    "def generate_ecc_key_pair():\n",
    "    key = ECC.generate(curve='P-256')\n",
    "    private_key = key.export_key(format='PEM')\n",
    "    public_key = key.public_key().export_key(format='PEM')\n",
    "    return private_key, public_key\n",
    "\n",
    "# Create a new DataFrame to store encrypted data\n",
    "df_encrypted = pd.DataFrame()\n",
    "\n",
    "# Generate AES key\n",
    "aes_key = generate_aes_key()\n",
    "\n",
    "# Generate ECC key pair\n",
    "private_key, public_key = generate_ecc_key_pair()\n",
    "\n",
    "# Encrypt each cell in the DataFrame using AES and store in df_encrypted\n",
    "for column in df_groups_users.columns:\n",
    "    df_encrypted[column] = df_groups_users[column].apply(lambda value: encrypt_data_aes(aes_key, str(value)))\n",
    "\n",
    "# Save the encrypted DataFrame to an Excel file\n",
    "df_encrypted.to_excel('Encrypted_GroupedUsers.xlsx', index=False)\n",
    "\n",
    "print(\"Data encrypted with AES and ECC and saved to Encrypted_GroupedUsers.xlsx\")\n",
    "\n",
    "# Read the encrypted DataFrame from Excel\n",
    "df_encrypted_read = pd.read_excel('Encrypted_GroupedUsers.xlsx')\n",
    "\n",
    "# Decrypt the data\n",
    "for column in df_encrypted_read.columns:\n",
    "    df_encrypted_read[column] = df_encrypted_read[column].apply(lambda value: decrypt_data_aes(aes_key, value))\n",
    "\n",
    "print(\"Data decrypted:\")\n",
    "print(df_encrypted_read)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9564bb60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
